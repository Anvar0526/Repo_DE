import os
import sys
import json
import pandas as pd
import requests
from sqlalchemy import create_engine, text
from airflow.models import Variable


def download_moex_stocks(**context):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ü–∏–π MOEX –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å –≤ JSON —Ñ–∞–π–ª—ã.
    
    –õ–æ–≥–∏–∫–∞:
    1. –ß–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ /opt/airflow/dags/config.json
    2. –°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É /opt/airflow/dags/data/ –µ—Å–ª–∏ –Ω–µ—Ç
    3. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ JSON —Ñ–∞–π–ª—ã (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å)
    4. –°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å MOEX API –¥–ª—è –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    5. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç pandas DataFrame –≤ JSON —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤: JSON task –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å PostgreSQL
    
    Args:
        context: Airflow context —Å yesterday_ds (–¥–∞—Ç–∞ –∑–∞ –≤—á–µ—Ä–∞)
    
    Returns:
        str: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ "–î–∞—Ç–∞: YYYY-MM-DD, –í—Å–µ–≥–æ: N, –Ω–æ–≤—ã—Ö: N, –ø—Ä–æ–ø—É—â–µ–Ω–æ: N, –æ—à–∏–±–æ–∫: N"
    """
    dags_dir = os.environ.get("AIRFLOW__CORE__DAGS_FOLDER", "/opt/airflow/dags")
    data_dir = os.path.join(dags_dir, "data")
    os.makedirs(data_dir, exist_ok=True)
    
    date_str = context['yesterday_ds']
    
    config_path = os.path.join(dags_dir, "config.json")
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω config.json: {len(config)} —Ç–∏–∫–µ—Ä–æ–≤")
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå config.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ {config_path}: {e}")
    
    existing_files = {f for f in os.listdir(data_dir) if f.endswith('.json')}
    print(f"üìÇ –°—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(existing_files)}")
    
    success_count = 0
    new_count = 0
    error_count = 0
    
    for ticker, info in config.items():
        filename = f"{ticker}_{date_str}.json"
        
        if filename in existing_files:
            print(f"‚è≠Ô∏è {filename} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            success_count += 1
            continue
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–∞—é {info['name']} ({ticker})")
        
        url = f"https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json?iss.meta=off&iss.only=history&from={date_str}"
        
        try:
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'history' in data and 'data' in data['history'] and len(data['history']['data']) > 0:
                    df = pd.DataFrame(
                        data['history']['data'], 
                        columns=data['history']['columns']
                    )
                    
                    tmp_filename = f"{data_dir}/{ticker}_{date_str}.tmp"
                    df.to_json(tmp_filename, orient='records', date_format='iso', indent=2)
                    os.rename(tmp_filename, f"{data_dir}/{filename}")
                    
                    print(f"‚úÖ {ticker}: {len(df)} –∑–∞–ø–∏—Å–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
                    success_count += 1
                    new_count += 1
                else:
                    print(f"‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker} –∑–∞ {date_str}")
                    error_count += 1
            else:
                print(f"‚ùå HTTP {response.status_code} –¥–ª—è {ticker}")
                error_count += 1
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ {ticker}: {str(e)}")
            error_count += 1
    
    result = f"–î–∞—Ç–∞: {date_str}, –í—Å–µ–≥–æ: {len(config)}, –Ω–æ–≤—ã—Ö: {new_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {success_count-new_count}, –æ—à–∏–±–æ–∫: {error_count}"
    print(f"üéâ –ó–∞–ø—É—Å–∫ {context['ds']} ‚Üí –î–∞–Ω–Ω—ã–µ –∑–∞ {date_str}: {result}")
    return result


def download_moex_stocks_postgres(**context):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ü–∏–π MOEX –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å –≤ PostgreSQL.
    
    –õ–æ–≥–∏–∫–∞:
    1. –ß–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ /opt/airflow/dags/config.json  
    2. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ PostgreSQL —á–µ—Ä–µ–∑ Airflow Variables (postgres_host, etc.)
    3. –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É moex_stock_history (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    4. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞:
       - –°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å MOEX API (TQBR, –¥–∞—Ç–∞=–≤—á–µ—Ä–∞)
       - –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç DataFrame (–¥–æ–±–∞–≤–ª—è–µ—Ç ticker/board, –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏)
       - –í—Å—Ç–∞–≤–ª—è–µ—Ç —á–µ—Ä–µ–∑ pandas.to_sql() —Å PRIMARY KEY –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–µ–π
    5. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–≥—Ä—É–∑–∫–∏
    
    –¢–∞–±–ª–∏—Ü–∞: moex_stock_history(trade_date, ticker, board, close, open, high, low, volume, value)
    
    Args:
        context: Airflow context —Å yesterday_ds (–¥–∞—Ç–∞ –∑–∞ –≤—á–µ—Ä–∞)
    
    Returns:
        str: "[PG] YYYY-MM-DD: N —Ç–∏–∫–µ—Ä–æ–≤, N —Å—Ç—Ä–æ–∫"
    """
    dags_dir = os.environ.get("AIRFLOW__CORE__DAGS_FOLDER", "/opt/airflow/dags")
    config_path = os.path.join(dags_dir, "config.json")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"‚úÖ [PG] –ó–∞–≥—Ä—É–∂–µ–Ω config.json: {len(config)} —Ç–∏–∫–µ—Ä–æ–≤")
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå [PG] config.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
    
    db_host = Variable.get("postgres_host", default_var="localhost")
    db_port = Variable.get("postgres_port", default_var="5432")
    db_name = Variable.get("postgres_db", default_var="airflow")
    db_user = Variable.get("postgres_user", default_var="airflow")
    db_password = Variable.get("postgres_password", default_var="airflow")
    
    connection_string = f"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"
    engine = create_engine(connection_string)
    
    
    CREATE_TABLE_SQL = """
    CREATE TABLE IF NOT EXISTS moex_stock_history (
        trade_date DATE,
        ticker VARCHAR(20),
        board VARCHAR(10),
        close DECIMAL(15,2),
        open DECIMAL(15,2),
        high DECIMAL(15,2),
        low DECIMAL(15,2),
        volume BIGINT,
        value DECIMAL(20,2),
        loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        PRIMARY KEY (trade_date, ticker, board)
    );
    CREATE INDEX IF NOT EXISTS idx_ticker_date ON moex_stock_history(ticker, trade_date);
    """
    
    with engine.connect() as conn:
        conn.execute(text(CREATE_TABLE_SQL))
    
    date_str = context['yesterday_ds']
    success_count = 0
    inserted_rows = 0
    
    for ticker, info in config.items():
        print(f"[PG] üìä {info['name']} ({ticker})")
        
        url = f"https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json?iss.meta=off&iss.only=history&from={date_str}"
        
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if 'history' in data and data['history']['data']:
                    df = pd.DataFrame(data['history']['data'], columns=data['history']['columns'])
                    
                    if len(df) > 0:
                        df['ticker'] = ticker
                        df['board'] = 'TQBR'
                        df = df.rename(columns={
                            'CLOSE': 'close', 'OPEN': 'open', 'HIGH': 'high', 'LOW': 'low',
                            'VOLUME': 'volume', 'VALUE': 'value', 'TRADEDATE': 'trade_date'
                        })
                        df = df[['trade_date', 'ticker', 'board', 'close', 'open', 'high', 'low', 'volume', 'value']]
                        df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date
                        
                        rows = df.to_sql('moex_stock_history', engine, if_exists='append', index=False, method='multi')
                        print(f"[PG] ‚úÖ {ticker}: {len(df)} —Å—Ç—Ä–æ–∫")
                        inserted_rows += len(df)
                    success_count += 1
        except Exception as e:
            print(f"[PG] ‚ùå {ticker}: {e}")
    
    result = f"[PG] {date_str}: {success_count} —Ç–∏–∫–µ—Ä–æ–≤, {inserted_rows} —Å—Ç—Ä–æ–∫"
    print(f"üéâ {result}")
    return result